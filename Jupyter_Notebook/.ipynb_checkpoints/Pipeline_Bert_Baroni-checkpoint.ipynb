{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from typing import List\n",
    "from collections import Counter\n",
    "import pickle5 as pickle \n",
    "from tqdm import trange\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "from transformers import (DistilBertTokenizerFast, DistilBertModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Vocab:\n",
    "\n",
    "    def __init__(self):\n",
    "        self._tok_counts = Counter()\n",
    "        self._id_to_tok = {}\n",
    "\n",
    "    def fit(self, data, word_list):\n",
    "        for sequence in data:\n",
    "            self._tok_counts.update([tok for tok in sequence if tok in word_list])\n",
    "\n",
    "        self._toks = ([\"</s>\", \"<unk>\"] +\n",
    "                      [tok for tok, _ in self._tok_counts.most_common()])\n",
    "        self._tok_to_id = {tok: i for i, tok in enumerate(self._toks)}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._toks)\n",
    "    \n",
    "class Tokenizer:\n",
    "\n",
    "    def __init__(self):\n",
    "        self._t = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")\n",
    "    def words(self, sequences: List[str]):\n",
    "        return [s.split() for s in sequences]\n",
    "\n",
    "    def __call__(self, sequences: List[str]):\n",
    "        words = self.words(sequences)\n",
    "        subw = self._t.batch_encode_plus(words,\n",
    "                                         is_split_into_words=True,\n",
    "                                         padding=True)\n",
    "        return words, subw\n",
    "\n",
    "class EmbedAverages(torch.nn.Module):\n",
    "    def __init__(self, n_words, dim):\n",
    "        super().__init__()\n",
    "        # matrix of wordvector sums\n",
    "        self.register_buffer(\"_sum\", torch.zeros(n_words, dim))\n",
    "        self.register_buffer(\"_counts\", torch.zeros(n_words, dtype=torch.long))\n",
    "        self.register_buffer(\"_cov\", torch.zeros(n_words, dim, dim))\n",
    "    \n",
    "    def add(self, ix, vec):\n",
    "        self._counts[ix] += 1\n",
    "        self._sum[ix] += vec\n",
    "        self._cov[ix] += vec.reshape([len(vec), 1]) @ vec.reshape([1, len(vec)])\n",
    "    \n",
    "    def get_mean_covariance(self, ix):\n",
    "#         print(\"self._counts[ix]\", self._counts[ix])\n",
    "#         print(\"self._sum[ix]\", self._sum[ix])\n",
    "        \n",
    "        mean = self._sum[ix] / self._counts[ix]\n",
    "        d = len(mean)\n",
    "        cov = self._cov[ix] / self._counts[ix] - mean.reshape([d, 1])  @ mean.reshape([1, d])\n",
    "        cov = .001 * torch.eye(d) + cov\n",
    "        return mean, cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_kl(wordpair):\n",
    "    # Get the mean vectors and covariance matrices for the two words in the word pair\n",
    "    mean1, covariance_matrix1 = embavg.get_mean_covariance(vocab._tok_to_id.get(wordpair[0])) \n",
    "    mean2, covariance_matrix2 = embavg.get_mean_covariance(vocab._tok_to_id.get(wordpair[1])) \n",
    "    \n",
    "    # Create PyTorch multivariate normal distributions using the mean vectors and covariance matrices\n",
    "    p = torch.distributions.multivariate_normal.MultivariateNormal(mean1, covariance_matrix=covariance_matrix1)\n",
    "    q = torch.distributions.multivariate_normal.MultivariateNormal(mean2, covariance_matrix=covariance_matrix2)\n",
    "\n",
    "    # Calculate the KL divergence between the two distributions\n",
    "    kl = torch.distributions.kl.kl_divergence(p, q)\n",
    "\n",
    "    return kl.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def import_baroni(neg_file, pos_file):\n",
    "    filenames = [\"neg_file\", \"pos_file\"]\n",
    "\n",
    "    for i, file in enumerate([neg_file, pos_file]):\n",
    "        globals()['results_{}'.format(filenames[i])] = []\n",
    "        \n",
    "        with open(file) as f:\n",
    "            line = f.readline()\n",
    "            while line:\n",
    "                globals()['results_{}'.format(filenames[i])].append(line.replace(\"-n\", \"\").replace(\"\\n\", \"\").strip(\"\").split(\"\\t\"))\n",
    "                line = f.readline()\n",
    "        f.close()\n",
    "\n",
    "    baroni = sum(results_neg_file, []) + sum(results_pos_file, [])\n",
    "    baroni_set = set(baroni)\n",
    "\n",
    "    return results_neg_file, results_pos_file, baroni, baroni_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5163\n"
     ]
    }
   ],
   "source": [
    "# Open the file in read mode\n",
    "with open(\"../data_distrembed/roen.vocab\", \"r\") as f:\n",
    "    # Read the contents of the file\n",
    "    contents = f.read()\n",
    "\n",
    "print(len(contents))  # prints the contents of the file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_file = \"../Data_Shared/eacl2012-data/negative-examples.txtinput\"\n",
    "pos_file = \"../Data_Shared/eacl2012-data/positive-examples.txtinput\"\n",
    "results_neg_file, results_pos_file, baroni, baroni_set = import_baroni(neg_file, pos_file)\n",
    "\n",
    "with open('../Data_Shared/wiki_subtext_preprocess.pickle', 'rb') as handle:\n",
    "        seqs = pickle.load(handle)\n",
    "\n",
    "seqs = seqs[:100000]\n",
    "\n",
    "tok = Tokenizer()\n",
    "vocab = Vocab()\n",
    "vocab.fit(tok.words(seqs), baroni)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "embavg = torch.load('../data_distrembed/first100000.avgs.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "670\n",
      "Counter({'people': 113, 'gas': 113, 'song': 87, 'name': 84, 'system': 82, 'funeral': 70, 'music': 67, 'football': 66, 'company': 65, 'player': 63, 'race': 63, 'politician': 61, 'hotel': 57, 'district': 55, 'church': 54, 'member': 53, 'set': 52, 'animal': 52, 'list': 51, 'son': 50, 'area': 50, 'final': 49, 'black': 48, 'energy': 48, 'president': 46, 'day': 45, 'building': 44, 'school': 44, 'ship': 44, 'end': 43, 'army': 43, 'conversion': 41, 'house': 40, 'work': 39, 'official': 39, 'green': 37, 'range': 35, 'organization': 34, 'red': 33, 'premier': 33, 'car': 33, 'father': 33, 'chart': 33, 'information': 32, 'art': 31, 'book': 31, 'community': 30, 'department': 30, 'ten': 30, 'road': 30, 'election': 29, 'governor': 29, 'club': 29, 'joint': 29, 'collection': 28, 'council': 28, 'site': 28, 'hockey': 28, 'record': 27, 'coach': 27, 'poet': 27, 'oil': 27, 'driver': 27, 'man': 26, 'water': 24, 'association': 24, 'term': 23, 'science': 23, 'title': 23, 'point': 23, 'country': 23, 'hall': 22, 'love': 22, 'human': 22, 'singer': 22, 'performance': 22, 'officer': 22, 'right': 21, 'ceremony': 21, 'navy': 21, 'railway': 21, 'business': 20, 'aircraft': 20, 'show': 20, 'wife': 20, 'daughter': 20, 'tour': 20, 'journalist': 20, 'carbon': 19, 'color': 19, 'wood': 18, 'commission': 18, 'studio': 18, 'committee': 18, 'male': 18, 'professional': 17, 'contract': 17, 'change': 17, 'dog': 17, 'light': 17, 'artist': 17, 'crew': 17, 'contest': 16, 'attack': 16, 'comic': 16, 'nickname': 16, 'surface': 16, 'yellow': 16, 'military': 16, 'brigade': 16, 'representative': 15, 'post': 15, 'research': 15, 'engine': 15, 'heat': 15, 'software': 15, 'pope': 14, 'female': 14, 'sir': 14, 'strength': 14, 'polymer': 14, 'hospital': 14, 'basketball': 14, 'quarterback': 14, 'lady': 13, 'metro': 13, 'valley': 13, 'brother': 13, 'woman': 13, 'writer': 13, 'leader': 12, 'concert': 12, 'plant': 12, 'stream': 12, 'courthouse': 12, 'painting': 12, 'size': 11, 'businessman': 11, 'room': 11, 'corporation': 11, 'draft': 11, 'mother': 11, 'review': 11, 'agreement': 11, 'shrine': 11, 'text': 11, 'pearl': 11, 'opening': 11, 'ice': 11, 'locomotive': 11, 'machine': 11, 'concept': 11, 'monastery': 11, 'husband': 10, 'note': 10, 'fish': 10, 'fiber': 10, 'playing': 10, 'bronze': 10, 'screenwriter': 10, 'word': 9, 'bishop': 9, 'cafe': 9, 'magazine': 9, 'game': 9, 'edge': 9, 'meat': 9, 'investment': 9, 'snake': 9, 'practice': 9, 'pilot': 9, 'piece': 9, 'turkey': 9, 'slalom': 9, 'gate': 9, 'box': 9, 'cat': 9, 'wall': 8, 'entrance': 8, 'encyclopedia': 8, 'treatment': 8, 'child': 8, 'prose': 8, 'cost': 8, 'produce': 8, 'wind': 8, 'horse': 8, 'bridge': 8, 'solid': 8, 'highway': 8, 'orange': 8, 'value': 8, 'engineering': 8, 'receiver': 8, 'vi': 7, 'vehicle': 7, 'anniversary': 7, 'theology': 7, 'dinner': 7, 'section': 7, 'musician': 7, 'ability': 7, 'solution': 7, 'soldier': 7, 'eating': 7, 'letter': 7, 'floor': 7, 'educator': 7, 'artillery': 7, 'racing': 7, 'screen': 7, 'rain': 7, 'cancer': 7, 'fuel': 7, 'twenty': 7, 'liquid': 7, 'chair': 6, 'era': 6, 'castle': 6, 'travel': 6, 'entertainment': 6, 'dancing': 6, 'height': 6, 'thirty': 6, 'statement': 6, 'temperature': 6, 'radius': 6, 'ban': 6, 'milk': 6, 'firm': 6, 'gun': 6, 'voice': 6, 'criminal': 6, 'iv': 6, 'suburb': 6, 'eagle': 6, 'golf': 6, 'care': 5, 'priest': 5, 'food': 5, 'flower': 5, 'superior': 5, 'movie': 5, 'leg': 5, 'representation': 5, 'diplomat': 5, 'teacher': 5, 'housing': 5, 'radiation': 5, 'chemical': 5, 'drummer': 5, 'winner': 5, 'occupation': 5, 'platform': 5, 'medium': 5, 'journey': 5, 'cold': 5, 'cannon': 5, 'scientist': 5, 'manual': 5, 'turnpike': 5, 'curve': 5, 'skier': 5, 'consumption': 5, 'border': 5, 'economics': 5, 'jean': 5, 'host': 5, 'reliability': 5, 'buffalo': 5, 'theater': 4, 'chapel': 4, 'saying': 4, 'lecturer': 4, 'cemetery': 4, 'mail': 4, 'manor': 4, 'disease': 4, 'conflict': 4, 'speaker': 4, 'discussion': 4, 'wine': 4, 'dramatist': 4, 'dancer': 4, 'bread': 4, 'athlete': 4, 'boat': 4, 'pine': 4, 'servant': 4, 'pair': 4, 'kick': 4, 'computer': 4, 'tip': 4, 'cool': 4, 'dean': 4, 'submarine': 4, 'meeting': 4, 'mule': 4, 'wave': 4, 'payment': 4, 'twelve': 4, 'cricketer': 4, 'facility': 4, 'cricket': 4, 'organist': 4, 'physician': 4, 'motorcycle': 4, 'tool': 4, 'winger': 4, 'baby': 4, 'prefecture': 4, 'merchant': 3, 'ancestor': 3, 'furniture': 3, 'antiquity': 3, 'decree': 3, 'document': 3, 'monarch': 3, 'reelection': 3, 'status': 3, 'recovery': 3, 'apple': 3, 'adult': 3, 'passion': 3, 'scholar': 3, 'spiral': 3, 'eleven': 3, 'cheese': 3, 'standing': 3, 'compensation': 3, 'orator': 3, 'doctor': 3, 'equipment': 3, 'geometry': 3, 'depth': 3, 'crystal': 3, 'consumer': 3, 'resident': 3, 'mathematics': 3, 'vocalist': 3, 'publisher': 3, 'attorney': 3, 'deer': 3, 'communication': 3, 'storm': 3, 'campsite': 3, 'walk': 3, 'vessel': 3, 'tower': 3, 'covering': 3, 'symbol': 3, 'crusade': 3, 'champagne': 3, 'theatre': 3, 'olive': 3, 'fly': 3, 'missile': 3, 'motto': 3, 'rate': 3, 'chancellor': 3, 'sunlight': 3, 'taste': 3, 'artwork': 3, 'murder': 3, 'therapy': 3, 'sunshine': 3, 'soccer': 3, 'principle': 3, 'publication': 3, 'postgraduate': 3, 'signal': 3, 'petroleum': 3, 'rector': 3, 'pianist': 3, 'knife': 3, 'restaurant': 3, 'sociologist': 3, 'declaration': 3, 'security': 3, 'caucus': 3, 'motorway': 3, 'epic': 3, 'biology': 3, 'cottage': 3, 'dish': 3, 'priory': 3, 'worm': 2, 'difference': 2, 'bull': 2, 'seminary': 2, 'ruler': 2, 'advocate': 2, 'cowboy': 2, 'humanist': 2, 'pain': 2, 'courtroom': 2, 'student': 2, 'aristocrat': 2, 'victim': 2, 'illness': 2, 'velocity': 2, 'surprise': 2, 'editor': 2, 'convention': 2, 'performer': 2, 'lamb': 2, 'dealer': 2, 'moratorium': 2, 'ticket': 2, 'gauge': 2, 'pipe': 2, 'cradle': 2, 'institution': 2, 'odyssey': 2, 'documentary': 2, 'clerk': 2, 'gunner': 2, 'pocket': 2, 'math': 2, 'fruit': 2, 'radar': 2, 'surgeon': 2, 'grove': 2, 'teaching': 2, 'whisky': 2, 'spacecraft': 2, 'sport': 2, 'shareholder': 2, 'memorandum': 2, 'fork': 2, 'procedure': 2, 'aide': 2, 'piracy': 2, 'royalty': 2, 'nut': 2, 'acid': 2, 'crime': 2, 'dictionary': 2, 'inn': 2, 'vicinity': 2, 'decoration': 2, 'chamber': 2, 'belief': 2, 'bear': 2, 'battleship': 2, 'commerce': 2, 'biologist': 2, 'sailor': 2, 'automobile': 2, 'violinist': 2, 'rugby': 2, 'archbishop': 2, 'linguist': 2, 'convent': 2, 'affection': 2, 'sixty': 2, 'dance': 2, 'initiation': 2, 'mixture': 2, 'stereo': 2, 'pathology': 2, 'fox': 2, 'slogan': 2, 'corridor': 2, 'barrier': 2, 'medicine': 2, 'environmentalist': 2, 'experiment': 2, 'snail': 2, 'cow': 2, 'deity': 2, 'lion': 2, 'logo': 2, 'passageway': 1, 'disability': 1, 'pet': 1, 'epistle': 1, 'spokesman': 1, 'message': 1, 'turbine': 1, 'registry': 1, 'baroness': 1, 'tutor': 1, 'palace': 1, 'garment': 1, 'kidnapping': 1, 'hair': 1, 'stepfather': 1, 'serpent': 1, 'prosecutor': 1, 'waiter': 1, 'joker': 1, 'gown': 1, 'sandwich': 1, 'decrease': 1, 'pontoon': 1, 'telegraph': 1, 'dove': 1, 'fencing': 1, 'swimming': 1, 'taxonomy': 1, 'lemon': 1, 'mistress': 1, 'condominium': 1, 'penthouse': 1, 'beverage': 1, 'virus': 1, 'pig': 1, 'pear': 1, 'alcohol': 1, 'flour': 1, 'paddle': 1, 'pirate': 1, 'feeling': 1, 'musket': 1, 'hawk': 1, 'shovel': 1, 'arthritis': 1, 'polyethylene': 1, 'explosive': 1, 'bend': 1, 'bird': 1, 'carbonate': 1, 'cassette': 1, 'melon': 1, 'relief': 1, 'transformation': 1, 'doctrine': 1, 'cosmology': 1, 'dwelling': 1, 'suit': 1, 'herb': 1, 'seed': 1, 'jet': 1, 'secretariat': 1, 'counterattack': 1, 'rifle': 1, 'ferry': 1, 'hamlet': 1, 'tavern': 1, 'militia': 1, 'sociology': 1, 'vicar': 1, 'typography': 1, 'believer': 1, 'panic': 1, 'bassist': 1, 'raven': 1, 'skating': 1, 'observatory': 1, 'ink': 1, 'alpha': 1, 'ox': 1, 'parent': 1, 'captivity': 1, 'secret': 1, 'volleyball': 1, 'cycling': 1, 'rig': 1, 'helicopter': 1, 'pizza': 1, 'quartz': 1, 'resin': 1, 'optimism': 1, 'competitiveness': 1, 'comment': 1, 'tree': 1, 'pollen': 1, 'migration': 1, 'vandalism': 1, 'undertaking': 1, 'gymnasium': 1, 'invitation': 1, 'carpenter': 1, 'elite': 1, 'mosque': 1, 'attitude': 1, 'compassion': 1, 'stipend': 1, 'seaplane': 1, 'seaman': 1, 'cook': 1, 'maple': 1, 'regent': 1, 'empress': 1, 'crab': 1, 'infant': 1, 'throne': 1, 'crowd': 1, 'tank': 1, 'bomber': 1, 'butcher': 1, 'balloon': 1, 'swan': 1, 'economist': 1, 'soprano': 1, 'swimmer': 1, 'percussionist': 1, 'saxophonist': 1, 'sprinter': 1, 'birthday': 1, 'boundary': 1, 'documentation': 1, 'license': 1, 'staple': 1, 'transaction': 1, 'trainer': 1, 'tie': 1, 'disco': 1, 'bottle': 1, 'rider': 1, 'hypnotherapy': 1, 'apparatus': 1, 'goalkeeper': 1, 'sedan': 1, 'pathologist': 1, 'physiology': 1, 'orchid': 1, 'sound': 1, 'shirt': 1, 'chemistry': 1, 'shop': 1, 'tea': 1, 'craftsman': 1, 'grandmother': 1, 'spoon': 1, 'spaceship': 1, 'organ': 1, 'rue': 1, 'obstruction': 1, 'cardinal': 1, 'hierarchy': 1, 'salesman': 1, 'detective': 1, 'storyteller': 1, 'reptile': 1, 'robin': 1, 'dad': 1, 'bacterium': 1, 'weapon': 1, 'pistol': 1, 'psychology': 1, 'coupe': 1, 'berry': 1, 'mom': 1, 'physiotherapy': 1, 'narrative': 1, 'electronics': 1, 'logic': 1, 'combustion': 1, 'relative': 1, 'goat': 1, 'cotton': 1, 'baronetcy': 1, 'pony': 1, 'beard': 1, 'bat': 1, 'hamster': 1, 'sack': 1, 'fear': 1, 'roast': 1, 'sweetness': 1, 'candy': 1, 'chef': 1, 'cookie': 1, 'dolphin': 1, 'boulevard': 1, 'columnist': 1, 'bounty': 1, 'resignation': 1})\n"
     ]
    }
   ],
   "source": [
    "print(len(vocab._tok_counts))\n",
    "print(vocab._tok_counts)\n",
    "for key, item in vocab._tok_counts.items():\n",
    "    if key not in baroni:\n",
    "        print(key, item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "baroni_pos_subset = [x for x in results_pos_file if x[0] in vocab._tok_counts and x[1] in vocab._tok_counts]\n",
    "baroni_neg_subset = [x for x in results_neg_file if x[0] in vocab._tok_counts and x[1] in vocab._tok_counts]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Wordpair  True label\n",
      "0        [acid, chemical]           1\n",
      "1    [affection, feeling]           1\n",
      "2     [aircraft, vehicle]           1\n",
      "3         [alpha, symbol]           1\n",
      "4        [antiquity, era]           1\n",
      "..                    ...         ...\n",
      "732     [woman, mistress]           0\n",
      "733         [wood, maple]           0\n",
      "734          [work, bird]           0\n",
      "735   [writer, dramatist]           0\n",
      "736        [writer, poet]           0\n",
      "\n",
      "[737 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# baroni_pos_subset, baroni_neg_subset = create_combined_subset(word_cov_matrices, results_neg_file, results_pos_file, combined_set)\n",
    "\n",
    "baroni_subset_label = []\n",
    "\n",
    "for i in baroni_pos_subset:\n",
    "    baroni_subset_label.append([i, 1])\n",
    "\n",
    "for i in baroni_neg_subset:\n",
    "    baroni_subset_label.append([i, 0])\n",
    "\n",
    "# MAKE DATAFRAME\n",
    "df1 = pd.DataFrame(baroni_subset_label, columns =['Wordpair', 'True label'])\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate KL and COS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 737/737 [00:47<00:00, 15.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Wordpair  True label      KL score\n",
      "0        [acid, chemical]           1  22588.404297\n",
      "1    [affection, feeling]           1  24089.642578\n",
      "2     [aircraft, vehicle]           1  22337.914062\n",
      "3         [alpha, symbol]           1  47081.132812\n",
      "4        [antiquity, era]           1  34338.492188\n",
      "..                    ...         ...           ...\n",
      "732     [woman, mistress]           0  33531.156250\n",
      "733         [wood, maple]           0  25387.968750\n",
      "734          [work, bird]           0  37608.054688\n",
      "735   [writer, dramatist]           0  50024.500000\n",
      "736        [writer, poet]           0  19814.851562\n",
      "\n",
      "[737 rows x 3 columns]\n",
      "KL AP:  0.4169200462853768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# CALCULATE KL and COS\n",
    "baroni_subset_kl = []\n",
    "baroni_subset_cos = []\n",
    "\n",
    "for wordpair in tqdm((baroni_pos_subset + baroni_neg_subset)):\n",
    "    baroni_subset_kl.append(calculate_kl(wordpair))\n",
    "    # baroni_subset_cos.append(cosine_similarity(ft.get_word_vector(wordpair[0]).numpy(), ft.get_word_vector(wordpair[1]).numpy()))\n",
    "\n",
    "df1['KL score'] = baroni_subset_kl\n",
    "# df1['COS score'] = baroni_subset_cos\n",
    "\n",
    "# with open('df1.pickle', 'wb') as handle:\n",
    "#     pickle.dump(df1, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "print(df1)\n",
    "# print(\"COS AP: \", average_precision_score(df1[\"True label\"], df1[\"COS score\"]))\n",
    "print(\"KL AP: \", average_precision_score(df1[\"True label\"], df1[\"KL score\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
