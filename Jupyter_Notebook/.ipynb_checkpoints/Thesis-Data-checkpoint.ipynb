{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "\n",
    "import fasttext\n",
    "import fasttext.util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperlex load (i dont use yet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WORD1</th>\n",
       "      <th>WORD2</th>\n",
       "      <th>POS</th>\n",
       "      <th>TYPE</th>\n",
       "      <th>AVG_SCORE</th>\n",
       "      <th>AVG_SCORE_0_10</th>\n",
       "      <th>STD</th>\n",
       "      <th>SCORES..</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>...</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>conflict</td>\n",
       "      <td>disagreement</td>\n",
       "      <td>N</td>\n",
       "      <td>r-hyp-1</td>\n",
       "      <td>5.20</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1.25</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>advance</td>\n",
       "      <td>take</td>\n",
       "      <td>V</td>\n",
       "      <td>no-rel</td>\n",
       "      <td>1.42</td>\n",
       "      <td>2.37</td>\n",
       "      <td>1.66</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>trail</td>\n",
       "      <td>follow</td>\n",
       "      <td>V</td>\n",
       "      <td>hyp-2</td>\n",
       "      <td>4.31</td>\n",
       "      <td>7.18</td>\n",
       "      <td>1.86</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mason</td>\n",
       "      <td>worker</td>\n",
       "      <td>N</td>\n",
       "      <td>hyp-3</td>\n",
       "      <td>4.50</td>\n",
       "      <td>7.5</td>\n",
       "      <td>1.76</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aura</td>\n",
       "      <td>light</td>\n",
       "      <td>N</td>\n",
       "      <td>hyp-1</td>\n",
       "      <td>3.69</td>\n",
       "      <td>6.15</td>\n",
       "      <td>1.86</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "0     WORD1         WORD2 POS     TYPE AVG_SCORE AVG_SCORE_0_10   STD  \\\n",
       "0  conflict  disagreement   N  r-hyp-1      5.20           8.67  1.25   \n",
       "1   advance          take   V   no-rel      1.42           2.37  1.66   \n",
       "2     trail        follow   V    hyp-2      4.31           7.18  1.86   \n",
       "3     mason        worker   N    hyp-3      4.50            7.5  1.76   \n",
       "4      aura         light   N    hyp-1      3.69           6.15  1.86   \n",
       "\n",
       "0 SCORES.. NaN NaN  ... NaN NaN NaN NaN NaN NaN   NaN   NaN   NaN   NaN  \n",
       "0        5   6   6  ...   6   5   2   6   4   6  None  None  None  None  \n",
       "1        3   0   3  ...   0   5   0   0   1   2     3     0  None  None  \n",
       "2        4   4   6  ...   6   6   6   3   0   4     3     6     6  None  \n",
       "3        6   6   4  ...   6   3   6   3   5   0     5     6  None  None  \n",
       "4        4   5   3  ...   6   0   3   6   3   0     4     5     5  None  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = \"../Data/hyperlex-data/hyperlex-all.txt\"\n",
    "\n",
    "results = []\n",
    "with open(file) as f:\n",
    "    line = f.readline()\n",
    "    while line:\n",
    "        results.append(line.strip().split(\" \"))\n",
    "        line = f.readline()\n",
    "f.close()\n",
    "\n",
    "HyperLex = pd.DataFrame(results)\n",
    "HyperLex.columns = HyperLex.iloc[0]\n",
    "HyperLex = HyperLex.iloc[1:].reset_index(drop=True)\n",
    "\n",
    "HyperLex.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load baroni dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_file = \"../Data_shared/eacl2012-data/negative-examples.txtinput\"\n",
    "pos_file = \"../Data_shared/eacl2012-data/positive-examples.txtinput\"\n",
    "filenames = [\"neg_file\", \"pos_file\"]\n",
    "\n",
    "\n",
    "for i, file in enumerate([neg_file, pos_file]):\n",
    "    globals()['results_{}'.format(filenames[i])] = []\n",
    "    \n",
    "    with open(file) as f:\n",
    "        line = f.readline()\n",
    "        while line:\n",
    "            globals()['results_{}'.format(filenames[i])].append(line.replace(\"-n\", \"\").replace(\"\\n\", \"\").strip(\"\").split(\"\\t\"))\n",
    "            line = f.readline()\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the length of all words in baroni:  5540\n",
      "number of unique in baroni:  1478\n"
     ]
    }
   ],
   "source": [
    "baroni = sum(results_neg_file, []) + sum(results_pos_file, [])\n",
    "set_baroni = set(baroni)\n",
    "\n",
    "print(\"the length of all words in baroni: \", len(baroni))\n",
    "print(\"number of unique in baroni: \", len(set(set_baroni)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load wikipedia data(sub)set \n",
    "Here I take a subset from the wikipedia data and create a method to substract a set of context vectors.\n",
    "\n",
    "I found the most common word in the 4 text is \"church\", i use that for further testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ran this on the workstation and copied it into the notebook\n",
    "import ast\n",
    "\n",
    "with open('../Data_shared/wiki_subset.txt') as file:\n",
    "    data = file.read()\n",
    "\n",
    "wikidata = ast.literal_eval(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre processing the wikipedia dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np  \n",
    "\n",
    "def text_preprocessing(\n",
    "    text:list,\n",
    "    punctuations = r'''!()-[]{};:'\"\\,<>./?@#$%^&*_“~''',\n",
    "    stop_words=['and', 'a', 'is', 'the', 'in', 'be', 'will']\n",
    "    )->list:\n",
    "    \"\"\"\n",
    "    A method to preproces text\n",
    "    \"\"\"\n",
    "    for x in text.lower(): \n",
    "        if x in punctuations: \n",
    "            text = text.replace(x, \"\")\n",
    "\n",
    "    # Removing words that have numbers in them\n",
    "    text = re.sub(r'\\w*\\d\\w*', '', text)\n",
    "\n",
    "    # Removing digits\n",
    "    text = re.sub(r'[0-9]+', '', text)\n",
    "\n",
    "    # Cleaning the whitespaces\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    # Setting every word to lower\n",
    "    text = text.lower()\n",
    "\n",
    "    # Converting all our text to a list \n",
    "    text = text.split(' ')\n",
    "\n",
    "    # Droping empty strings\n",
    "    text = [x for x in text if x!='']\n",
    "\n",
    "    # Droping stop words\n",
    "#     text = [x for x in text if x not in stop_words]\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### apply preprocessing to wikidata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:19<00:00, 507.45it/s]\n"
     ]
    }
   ],
   "source": [
    "# Cleaning the text\n",
    "texts = [x for x in wikidata['text']]\n",
    "\n",
    "wiki_all_text = []\n",
    "\n",
    "for text in tqdm(texts):\n",
    "    # Appending to the all text list\n",
    "    text = text_preprocessing(text)\n",
    "    wiki_all_text += text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['yangliuqing',\n",
       " 'is',\n",
       " 'a',\n",
       " 'market',\n",
       " 'town',\n",
       " 'in',\n",
       " 'xiqing',\n",
       " 'district',\n",
       " 'in',\n",
       " 'the']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_all_text[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a context dictionairy from wiki subset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4556903it [00:31, 146322.34it/s]\n"
     ]
    }
   ],
   "source": [
    "# Defining the window for context\n",
    "window = 5\n",
    "\n",
    "# Creating a dictionary entry for each word in the texts\n",
    "context_dict = { i : list() for i in set(wiki_all_text)}\n",
    "\n",
    "\n",
    "for i, word in tqdm(enumerate(wiki_all_text)):\n",
    "    for w in range(window):\n",
    "        # Getting the context that is ahead by *window* words\n",
    "        \n",
    "        if i + 1 + w < len(wiki_all_text):\n",
    "            context_dict[word].append(wiki_all_text[(i + 1 + w)]) \n",
    "        # Getting the context that is behind by *window* words    \n",
    "        if i - w - 1 >= 0:\n",
    "            context_dict[word].append(wiki_all_text[(i - w - 1)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# use fasttext to get word vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get pre trained fastext model code is now replaced with a load file\n",
    "\n",
    "# ft = fasttext.load_model('./data/cc.en.300.bin')\n",
    "# ft.get_dimension()\n",
    "# fasttext.util.reduce_model(ft, 100)\n",
    "# ft.get_dimension()\n",
    "\n",
    "# ft.save_model(\"ft_reduced_100.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "ft = fasttext.load_model(\"../Data/ft_reduced_100.bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EMPIRICAL COVARIANCES\n",
    "the actual implementation of the equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique words in baroni:  1478\n",
      "words that are represented by the wiki subset:  1448\n"
     ]
    }
   ],
   "source": [
    "# Extract words that appear in both baroni as in wikidata subset\n",
    "combined_set = set(wiki_all_text)&set(set_baroni)\n",
    "print(\"unique words in baroni: \", len(set(set_baroni)))\n",
    "print(\"words that are represented by the wiki subset: \", len(combined_set))\n",
    "\n",
    "combined_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = np.zeros((100,100))\n",
    "\n",
    "test_words = ['church', \n",
    "              'building']\n",
    "\n",
    "covariance = {}\n",
    "\n",
    "for word in tqdm(combined_set):\n",
    "    for c_word in context_dict[word]:\n",
    "        w = ft.get_word_vector(word)\n",
    "        total += np.outer((ft.get_word_vector(c_word) - w), (ft.get_word_vector(c_word) - w))\n",
    "    \n",
    "    covariance[word] = (total / (len(context_dict[word]) * window))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create a combined set with enough context to keep from getting PositiveDefinite() error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1318"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_set_context_len = {}\n",
    "\n",
    "for i in combined_set:\n",
    "    combined_set_context_len[i] = len(context_dict[i])\n",
    "\n",
    "# coriander triggered positive definite warning context of coriander is 20 words\n",
    "combined_set_context_len['coriander']\n",
    "\n",
    "combined_set_30plus = [x for x , key in combined_set_context_len.items() if key > 30]\n",
    "len(combined_set_30plus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(19.7034, dtype=torch.float64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "mean1 = ft.get_word_vector('church')\n",
    "covariance_matrix1 = covariance[\"church\"]\n",
    "# multiplyDiagonal(covariance_matrix1, 0.5)\n",
    "\n",
    "mean2 = ft.get_word_vector('building')\n",
    "covariance_matrix2 = covariance[\"building\"]\n",
    "# multiplyDiagonal(covariance_matrix2, 0.5)\n",
    "\n",
    "mean1 = torch.from_numpy(mean1)\n",
    "covariance_matrix1 = torch.from_numpy(covariance_matrix1)\n",
    "\n",
    "mean2 = torch.from_numpy(mean2)\n",
    "covariance_matrix2 = torch.from_numpy(covariance_matrix2)\n",
    "\n",
    "\n",
    "p = torch.distributions.multivariate_normal.MultivariateNormal(mean1, covariance_matrix=covariance_matrix1)\n",
    "q = torch.distributions.multivariate_normal.MultivariateNormal(mean2, covariance_matrix=covariance_matrix2)\n",
    "\n",
    "\n",
    "\n",
    "torch.distributions.kl.kl_divergence(p, q)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 2]\n",
      " [3 4 5]\n",
      " [6 7 8]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2],\n",
       "       [3, 4, 5],\n",
       "       [6, 7, 8]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  In practice, it is also necessary to add a small ridge term \n",
    "#  δ > 0 to the diagonal of the matrix to regularize and avoid \n",
    "#  numerical problems when inverting - vilnis mccalumn\n",
    "\n",
    "def addDiagonal(matrix, x):\n",
    "    assert x < 1, f\"x greater than 0 expected, got: {x}\"\n",
    "    \n",
    "    for i in range(len(matrix)):\n",
    "        matrix[i][i] = matrix[i][i] + x\n",
    "    \n",
    "    return matrix\n",
    "\n",
    "\n",
    "# a = np.arange(9).reshape(3,3)\n",
    "# print(a)\n",
    "# addDiagonal(a, 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baroni test set "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- count word occurence of baroni in wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baroni pos length:  1385\n",
      "baroni pos subset length:  1172\n",
      "baroni neg length:  1385\n",
      "baroni neg subset length:  1179\n"
     ]
    }
   ],
   "source": [
    "# create a baroni pos and neg dataset that only contains words from the combined word collection\n",
    "# so ones that are found in the wiki dataset \n",
    "\n",
    "results_neg_file\n",
    "results_pos_file\n",
    "baroni_pos_subset = [x for x in results_pos_file if x[0] in combined_set_30plus and x[1] in combined_set_30plus]\n",
    "baroni_neg_subset = [x for x in results_neg_file if x[0] in combined_set_30plus and x[1] in combined_set_30plus]\n",
    "\n",
    "print(\"baroni pos length: \", len(results_pos_file))\n",
    "print(\"baroni pos subset length: \",len(baroni_pos_subset))\n",
    "print(\"baroni neg length: \", len(results_neg_file))\n",
    "print(\"baroni neg subset length: \",len(baroni_neg_subset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wordpair</th>\n",
       "      <th>True label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[abstraction, concept]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[accusation, statement]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[ache, pain]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[acid, chemical]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[acoustics, discipline]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2346</th>\n",
       "      <td>[writer, dramatist]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2347</th>\n",
       "      <td>[writer, poet]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2348</th>\n",
       "      <td>[yellow, protein]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2349</th>\n",
       "      <td>[yesterday, discipline]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2350</th>\n",
       "      <td>[yesterday, subcommittee]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2351 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Wordpair  True label\n",
       "0        [abstraction, concept]           1\n",
       "1       [accusation, statement]           1\n",
       "2                  [ache, pain]           1\n",
       "3              [acid, chemical]           1\n",
       "4       [acoustics, discipline]           1\n",
       "...                         ...         ...\n",
       "2346        [writer, dramatist]           0\n",
       "2347             [writer, poet]           0\n",
       "2348          [yellow, protein]           0\n",
       "2349    [yesterday, discipline]           0\n",
       "2350  [yesterday, subcommittee]           0\n",
       "\n",
       "[2351 rows x 2 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baroni_subset_label = []\n",
    "\n",
    "for i in baroni_pos_subset:\n",
    "    baroni_subset_label.append([i, 1])\n",
    "\n",
    "for i in baroni_neg_subset:\n",
    "    baroni_subset_label.append([i, 0])\n",
    "\n",
    "df = pd.DataFrame(baroni_subset_label, columns =['Wordpair', 'True label'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KL divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "baroni_subset_kl = []\n",
    "\n",
    "for wordpair in (baroni_pos_subset + baroni_neg_subset):\n",
    "    mean1 = torch.from_numpy(ft.get_word_vector(wordpair[0]))\n",
    "    covariance_matrix1 = torch.from_numpy(covariance[wordpair[0]])\n",
    "    mean2 = torch.from_numpy(ft.get_word_vector(wordpair[1]))\n",
    "    covariance_matrix2 = torch.from_numpy(covariance[wordpair[1]])\n",
    "    \n",
    "    p = torch.distributions.multivariate_normal.MultivariateNormal(mean1, covariance_matrix=covariance_matrix1)\n",
    "    q = torch.distributions.multivariate_normal.MultivariateNormal(mean2, covariance_matrix=covariance_matrix2)\n",
    "\n",
    "    baroni_subset_kl.append(float(torch.distributions.kl.kl_divergence(p, q)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COS similairity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.linalg import norm\n",
    "from scipy.spatial import distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(a, b):\n",
    "    nominator = np.dot(a, b)\n",
    "    \n",
    "    a_norm = np.sqrt(np.sum(a**2))\n",
    "    b_norm = np.sqrt(np.sum(b**2))\n",
    "    \n",
    "    denominator = a_norm * b_norm\n",
    "    \n",
    "    cosine_similarity = nominator / denominator\n",
    "    \n",
    "    return cosine_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covariance[\"church\"].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "baroni_subset_cos = []\n",
    "\n",
    "for wordpair in (baroni_pos_subset + baroni_neg_subset):\n",
    "    A = covariance[wordpair[0]].flatten()\n",
    "    B = covariance[wordpair[1]].flatten()\n",
    "    baroni_subset_cos.append(cosine_similarity(A, B))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['KL score'] = baroni_subset_kl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['COS score 2'] = baroni_subset_cos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wordpair</th>\n",
       "      <th>True label</th>\n",
       "      <th>KL score</th>\n",
       "      <th>COS score</th>\n",
       "      <th>COS score 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[abstraction, concept]</td>\n",
       "      <td>1</td>\n",
       "      <td>3677.993391</td>\n",
       "      <td>0.004975</td>\n",
       "      <td>0.995025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[accusation, statement]</td>\n",
       "      <td>1</td>\n",
       "      <td>33120.671239</td>\n",
       "      <td>0.043247</td>\n",
       "      <td>0.956753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[ache, pain]</td>\n",
       "      <td>1</td>\n",
       "      <td>310.987227</td>\n",
       "      <td>0.001775</td>\n",
       "      <td>0.998225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[acid, chemical]</td>\n",
       "      <td>1</td>\n",
       "      <td>12.417440</td>\n",
       "      <td>0.003487</td>\n",
       "      <td>0.996513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[acoustics, discipline]</td>\n",
       "      <td>1</td>\n",
       "      <td>13.651013</td>\n",
       "      <td>0.005020</td>\n",
       "      <td>0.994980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2346</th>\n",
       "      <td>[writer, dramatist]</td>\n",
       "      <td>0</td>\n",
       "      <td>76.266101</td>\n",
       "      <td>0.015634</td>\n",
       "      <td>0.984366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2347</th>\n",
       "      <td>[writer, poet]</td>\n",
       "      <td>0</td>\n",
       "      <td>28.792145</td>\n",
       "      <td>0.002254</td>\n",
       "      <td>0.997746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2348</th>\n",
       "      <td>[yellow, protein]</td>\n",
       "      <td>0</td>\n",
       "      <td>20.560677</td>\n",
       "      <td>0.004944</td>\n",
       "      <td>0.995056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2349</th>\n",
       "      <td>[yesterday, discipline]</td>\n",
       "      <td>0</td>\n",
       "      <td>37.131087</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.999600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2350</th>\n",
       "      <td>[yesterday, subcommittee]</td>\n",
       "      <td>0</td>\n",
       "      <td>364.262543</td>\n",
       "      <td>0.008744</td>\n",
       "      <td>0.991256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2351 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Wordpair  True label      KL score  COS score  \\\n",
       "0        [abstraction, concept]           1   3677.993391   0.004975   \n",
       "1       [accusation, statement]           1  33120.671239   0.043247   \n",
       "2                  [ache, pain]           1    310.987227   0.001775   \n",
       "3              [acid, chemical]           1     12.417440   0.003487   \n",
       "4       [acoustics, discipline]           1     13.651013   0.005020   \n",
       "...                         ...         ...           ...        ...   \n",
       "2346        [writer, dramatist]           0     76.266101   0.015634   \n",
       "2347             [writer, poet]           0     28.792145   0.002254   \n",
       "2348          [yellow, protein]           0     20.560677   0.004944   \n",
       "2349    [yesterday, discipline]           0     37.131087   0.000400   \n",
       "2350  [yesterday, subcommittee]           0    364.262543   0.008744   \n",
       "\n",
       "      COS score 2  \n",
       "0        0.995025  \n",
       "1        0.956753  \n",
       "2        0.998225  \n",
       "3        0.996513  \n",
       "4        0.994980  \n",
       "...           ...  \n",
       "2346     0.984366  \n",
       "2347     0.997746  \n",
       "2348     0.995056  \n",
       "2349     0.999600  \n",
       "2350     0.991256  \n",
       "\n",
       "[2351 rows x 5 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
