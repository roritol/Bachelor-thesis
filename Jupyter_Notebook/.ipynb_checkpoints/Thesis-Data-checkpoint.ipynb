{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from collections import Counter\n",
    "\n",
    "import fasttext\n",
    "import fasttext.util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"/Users/rori/Documents/UVA_4/Thesis_git/Python_Code/baroniwiki_count.pickle\"\n",
    "\n",
    "with open(file, 'rb') as f:\n",
    "        baroniwiki_count = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperlex load (i dont use yet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WORD1</th>\n",
       "      <th>WORD2</th>\n",
       "      <th>POS</th>\n",
       "      <th>TYPE</th>\n",
       "      <th>AVG_SCORE</th>\n",
       "      <th>AVG_SCORE_0_10</th>\n",
       "      <th>STD</th>\n",
       "      <th>SCORES..</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>...</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>conflict</td>\n",
       "      <td>disagreement</td>\n",
       "      <td>N</td>\n",
       "      <td>r-hyp-1</td>\n",
       "      <td>5.20</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1.25</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>advance</td>\n",
       "      <td>take</td>\n",
       "      <td>V</td>\n",
       "      <td>no-rel</td>\n",
       "      <td>1.42</td>\n",
       "      <td>2.37</td>\n",
       "      <td>1.66</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>trail</td>\n",
       "      <td>follow</td>\n",
       "      <td>V</td>\n",
       "      <td>hyp-2</td>\n",
       "      <td>4.31</td>\n",
       "      <td>7.18</td>\n",
       "      <td>1.86</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mason</td>\n",
       "      <td>worker</td>\n",
       "      <td>N</td>\n",
       "      <td>hyp-3</td>\n",
       "      <td>4.50</td>\n",
       "      <td>7.5</td>\n",
       "      <td>1.76</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aura</td>\n",
       "      <td>light</td>\n",
       "      <td>N</td>\n",
       "      <td>hyp-1</td>\n",
       "      <td>3.69</td>\n",
       "      <td>6.15</td>\n",
       "      <td>1.86</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "0     WORD1         WORD2 POS     TYPE AVG_SCORE AVG_SCORE_0_10   STD  \\\n",
       "0  conflict  disagreement   N  r-hyp-1      5.20           8.67  1.25   \n",
       "1   advance          take   V   no-rel      1.42           2.37  1.66   \n",
       "2     trail        follow   V    hyp-2      4.31           7.18  1.86   \n",
       "3     mason        worker   N    hyp-3      4.50            7.5  1.76   \n",
       "4      aura         light   N    hyp-1      3.69           6.15  1.86   \n",
       "\n",
       "0 SCORES.. NaN NaN  ... NaN NaN NaN NaN NaN NaN   NaN   NaN   NaN   NaN  \n",
       "0        5   6   6  ...   6   5   2   6   4   6  None  None  None  None  \n",
       "1        3   0   3  ...   0   5   0   0   1   2     3     0  None  None  \n",
       "2        4   4   6  ...   6   6   6   3   0   4     3     6     6  None  \n",
       "3        6   6   4  ...   6   3   6   3   5   0     5     6  None  None  \n",
       "4        4   5   3  ...   6   0   3   6   3   0     4     5     5  None  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = \"../Data/hyperlex-data/hyperlex-all.txt\"\n",
    "\n",
    "results = []\n",
    "with open(file) as f:\n",
    "    line = f.readline()\n",
    "    while line:\n",
    "        results.append(line.strip().split(\" \"))\n",
    "        line = f.readline()\n",
    "f.close()\n",
    "\n",
    "HyperLex = pd.DataFrame(results)\n",
    "HyperLex.columns = HyperLex.iloc[0]\n",
    "HyperLex = HyperLex.iloc[1:].reset_index(drop=True)\n",
    "\n",
    "HyperLex.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load baroni dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_file = \"../Data_shared/eacl2012-data/negative-examples.txtinput\"\n",
    "pos_file = \"../Data_shared/eacl2012-data/positive-examples.txtinput\"\n",
    "filenames = [\"neg_file\", \"pos_file\"]\n",
    "\n",
    "\n",
    "for i, file in enumerate([neg_file, pos_file]):\n",
    "    globals()['results_{}'.format(filenames[i])] = []\n",
    "    \n",
    "    with open(file) as f:\n",
    "        line = f.readline()\n",
    "        while line:\n",
    "            globals()['results_{}'.format(filenames[i])].append(line.replace(\"-n\", \"\").replace(\"\\n\", \"\").strip(\"\").split(\"\\t\"))\n",
    "            line = f.readline()\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the length of all words in baroni:  5540\n",
      "number of unique in baroni:  1478\n"
     ]
    }
   ],
   "source": [
    "baroni = sum(results_neg_file, []) + sum(results_pos_file, [])\n",
    "baroni_set = set(baroni)\n",
    "\n",
    "print(\"the length of all words in baroni: \", len(baroni))\n",
    "print(\"number of unique in baroni: \", len(set(baroni_set)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load wikipedia data(sub)set \n",
    "Here I take a subset from the wikipedia data and create a method to substract a set of context vectors.\n",
    "\n",
    "I found the most common word in the 4 text is \"church\", i use that for further testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ran this on the workstation and copied it into the notebook\n",
    "import ast\n",
    "\n",
    "with open('../Data_shared/wiki_subset.txt') as file:\n",
    "    data = file.read()\n",
    "\n",
    "wikidata = ast.literal_eval(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre processing the wikipedia dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np  \n",
    "\n",
    "def text_preprocessing(\n",
    "    text:list,\n",
    "    punctuations = r'''!()-[]{};:'\"\\,<>./?@#$%^&*_“~''',\n",
    "    stop_words=['and', 'a', 'is', 'the', 'in', 'be', 'will']\n",
    "    )->list:\n",
    "    \"\"\"\n",
    "    A method to preproces text\n",
    "    \"\"\"\n",
    "    for x in text.lower(): \n",
    "        if x in punctuations: \n",
    "            text = text.replace(x, \"\")\n",
    "\n",
    "    # Removing words that have numbers in them\n",
    "    text = re.sub(r'\\w*\\d\\w*', '', text)\n",
    "\n",
    "    # Removing digits\n",
    "    text = re.sub(r'[0-9]+', '', text)\n",
    "\n",
    "    # Cleaning the whitespaces\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    # Setting every word to lower\n",
    "    text = text.lower()\n",
    "\n",
    "    # Converting all our text to a list \n",
    "    text = text.split(' ')\n",
    "\n",
    "    # Droping empty strings\n",
    "    text = [x for x in text if x!='']\n",
    "\n",
    "    # Droping stop words\n",
    "#     text = [x for x in text if x not in stop_words]\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### apply preprocessing to wikidata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:20<00:00, 488.92it/s]\n"
     ]
    }
   ],
   "source": [
    "# Cleaning the text\n",
    "texts = [x for x in wikidata['text']]\n",
    "\n",
    "wiki_all_text = []\n",
    "\n",
    "for text in tqdm(texts):\n",
    "    # Appending to the all text list\n",
    "    text = text_preprocessing(text)\n",
    "    wiki_all_text += text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['yangliuqing',\n",
       " 'is',\n",
       " 'a',\n",
       " 'market',\n",
       " 'town',\n",
       " 'in',\n",
       " 'xiqing',\n",
       " 'district',\n",
       " 'in',\n",
       " 'the']"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_all_text[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a context dictionairy from wiki subset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4556903it [00:23, 190331.61it/s]\n"
     ]
    }
   ],
   "source": [
    "# Defining the window for context\n",
    "window = 4\n",
    "\n",
    "# Creating a dictionary entry for each word in the texts\n",
    "context_dict = { i : list() for i in set(wiki_all_text)}\n",
    "\n",
    "\n",
    "for i, word in tqdm(enumerate(wiki_all_text)):\n",
    "    for w in range(window):\n",
    "        # Getting the context that is ahead by *window* words\n",
    "        \n",
    "        if i + 1 + w < len(wiki_all_text):\n",
    "            context_dict[word].append(wiki_all_text[(i + 1 + w)]) \n",
    "        # Getting the context that is behind by *window* words    \n",
    "        if i - w - 1 >= 0:\n",
    "            context_dict[word].append(wiki_all_text[(i - w - 1)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# use fasttext to get word vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "# get pre trained fastext model code is now replaced with a load file\n",
    "\n",
    "ft = fasttext.load_model('../Data/cc.en.300.bin')\n",
    "# ft.get_dimension()\n",
    "# fasttext.util.reduce_model(ft, 100)\n",
    "# ft.get_dimension()\n",
    "\n",
    "# ft.save_model(\"ft_reduced_100.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "ft = fasttext.load_model(\"../Data/ft_reduced_100.bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EMPIRICAL COVARIANCES\n",
    "the actual implementation of the equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique words in baroni:  1478\n",
      "words that are represented by the wiki subset:  1448\n"
     ]
    }
   ],
   "source": [
    "# Extract words that appear in both baroni as in wikidata subset\n",
    "combined_set = set(wiki_all_text)&set(baroni_set)\n",
    "print(\"unique words in baroni: \", len(set(baroni_set)))\n",
    "print(\"words that are represented by the wiki subset: \", len(combined_set))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1448/1448 [09:58<00:00,  2.42it/s]\n"
     ]
    }
   ],
   "source": [
    "covariance = {}\n",
    "\n",
    "\n",
    "for word in tqdm(combined_set):\n",
    "    total = np.zeros((300,300))\n",
    "    \n",
    "    for c_word in context_dict[word]:\n",
    "        w = ft.get_word_vector(word)\n",
    "        total += np.outer((ft.get_word_vector(c_word) - w), (ft.get_word_vector(c_word) - w))\n",
    "    \n",
    "    covariance[word] = (total / (len(context_dict[word]) * window))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create a combined set with enough context to keep from getting PositiveDefinite() error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1202"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_set_context_len = {}\n",
    "\n",
    "for i in combined_set:\n",
    "    combined_set_context_len[i] = len(context_dict[i])\n",
    "\n",
    "# coriander triggered positive definite warning context of coriander is 20 words\n",
    "combined_set_context_len['coriander']\n",
    "\n",
    "combined_set_30plus = [x for x , key in combined_set_context_len.items() if key > 50]\n",
    "len(combined_set_30plus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'addDiagonal' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-325c2cfdd534>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmean1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_word_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'abstraction'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcovariance_matrix1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcovariance\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"abstraction\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0maddDiagonal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcovariance_matrix1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmean2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_word_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'concept'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'addDiagonal' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "mean1 = ft.get_word_vector('abstraction')\n",
    "covariance_matrix1 = covariance[\"abstraction\"]\n",
    "addDiagonal(covariance_matrix1, 0.5)\n",
    "\n",
    "mean2 = ft.get_word_vector('concept')\n",
    "covariance_matrix2 = covariance[\"concept\"]\n",
    "addDiagonal(covariance_matrix2, 0.5)\n",
    "\n",
    "mean1 = torch.from_numpy(mean1)\n",
    "covariance_matrix1 = torch.from_numpy(covariance_matrix1)\n",
    "\n",
    "mean2 = torch.from_numpy(mean2)\n",
    "covariance_matrix2 = torch.from_numpy(covariance_matrix2)\n",
    "\n",
    "\n",
    "p = torch.distributions.multivariate_normal.MultivariateNormal(mean1, covariance_matrix=covariance_matrix1)\n",
    "q = torch.distributions.multivariate_normal.MultivariateNormal(mean2, covariance_matrix=covariance_matrix2)\n",
    "\n",
    "\n",
    "\n",
    "torch.distributions.kl.kl_divergence(p, q)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  In practice, it is also necessary to add a small ridge term \n",
    "#  δ > 0 to the diagonal of the matrix to regularize and avoid \n",
    "#  numerical problems when inverting - vilnis mccalumn\n",
    "\n",
    "def addDiagonal(matrix, x):\n",
    "    assert x < 1, f\"x greater than 0 expected, got: {x}\"\n",
    "    \n",
    "    for i in range(len(matrix)):\n",
    "        matrix[i][i] = matrix[i][i] + x\n",
    "    \n",
    "    return matrix\n",
    "\n",
    "\n",
    "# a = np.arange(9).reshape(3,3)\n",
    "# print(a)\n",
    "# addDiagonal(a, 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baroni test set "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- count word occurence of baroni in wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baroni pos length:  1385\n",
      "baroni pos subset length:  1028\n",
      "baroni neg length:  1385\n",
      "baroni neg subset length:  1046\n"
     ]
    }
   ],
   "source": [
    "# create a baroni pos and neg dataset that only contains words from the combined word collection\n",
    "# so ones that are found in the wiki dataset \n",
    "\n",
    "results_neg_file\n",
    "results_pos_file\n",
    "baroni_pos_subset = [x for x in results_pos_file if x[0] in combined_set_30plus and x[1] in combined_set_30plus]\n",
    "baroni_neg_subset = [x for x in results_neg_file if x[0] in combined_set_30plus and x[1] in combined_set_30plus]\n",
    "\n",
    "print(\"baroni pos length: \", len(results_pos_file))\n",
    "print(\"baroni pos subset length: \",len(baroni_pos_subset))\n",
    "print(\"baroni neg length: \", len(results_neg_file))\n",
    "print(\"baroni neg subset length: \",len(baroni_neg_subset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wordpair</th>\n",
       "      <th>True label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[abstraction, concept]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[accusation, statement]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[acid, chemical]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[acoustics, discipline]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[adjective, word]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2069</th>\n",
       "      <td>[writer, dramatist]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070</th>\n",
       "      <td>[writer, poet]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2071</th>\n",
       "      <td>[yellow, protein]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2072</th>\n",
       "      <td>[yesterday, discipline]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2073</th>\n",
       "      <td>[yesterday, subcommittee]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2074 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Wordpair  True label\n",
       "0        [abstraction, concept]           1\n",
       "1       [accusation, statement]           1\n",
       "2              [acid, chemical]           1\n",
       "3       [acoustics, discipline]           1\n",
       "4             [adjective, word]           1\n",
       "...                         ...         ...\n",
       "2069        [writer, dramatist]           0\n",
       "2070             [writer, poet]           0\n",
       "2071          [yellow, protein]           0\n",
       "2072    [yesterday, discipline]           0\n",
       "2073  [yesterday, subcommittee]           0\n",
       "\n",
       "[2074 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baroni_subset_label = []\n",
    "\n",
    "for i in baroni_pos_subset:\n",
    "    baroni_subset_label.append([i, 1])\n",
    "\n",
    "for i in baroni_neg_subset:\n",
    "    baroni_subset_label.append([i, 0])\n",
    "\n",
    "df = pd.DataFrame(baroni_subset_label, columns =['Wordpair', 'True label'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KL divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "baroni_subset_kl = []\n",
    "\n",
    "for wordpair in (baroni_pos_subset + baroni_neg_subset):\n",
    "    mean1 = torch.from_numpy(ft.get_word_vector(wordpair[0]))\n",
    "    covariance_matrix1 = torch.from_numpy(covariance[wordpair[0]])\n",
    "    addDiagonal(covariance_matrix1, 0.1)\n",
    "    mean2 = torch.from_numpy(ft.get_word_vector(wordpair[1]))\n",
    "    covariance_matrix2 = torch.from_numpy(covariance[wordpair[1]])\n",
    "    addDiagonal(covariance_matrix2, 0.1)\n",
    "    \n",
    "    p = torch.distributions.multivariate_normal.MultivariateNormal(mean1, covariance_matrix=covariance_matrix1)\n",
    "    q = torch.distributions.multivariate_normal.MultivariateNormal(mean2, covariance_matrix=covariance_matrix2)\n",
    "\n",
    "    baroni_subset_kl.append(float(torch.distributions.kl.kl_divergence(p, q)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['KL score'] = baroni_subset_kl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COS similairity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.linalg import norm\n",
    "from scipy.spatial import distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(a, b):\n",
    "    nominator = np.dot(a, b)\n",
    "    \n",
    "    a_norm = np.sqrt(np.sum(a**2))\n",
    "    b_norm = np.sqrt(np.sum(b**2))\n",
    "    \n",
    "    denominator = a_norm * b_norm\n",
    "    \n",
    "    cosine_similarity = nominator / denominator\n",
    "    \n",
    "    return cosine_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "baroni_subset_cos = []\n",
    "\n",
    "for wordpair in (baroni_pos_subset + baroni_neg_subset):\n",
    "    A = ft.get_word_vector(wordpair[0])\n",
    "    B = ft.get_word_vector(wordpair[1])\n",
    "    baroni_subset_cos.append(cosine_similarity(A, B))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['COS score'] = baroni_subset_cos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wordpair</th>\n",
       "      <th>True label</th>\n",
       "      <th>KL score</th>\n",
       "      <th>COS score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[abstraction, concept]</td>\n",
       "      <td>1</td>\n",
       "      <td>2.201361</td>\n",
       "      <td>0.370621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[accusation, statement]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.641579</td>\n",
       "      <td>0.477037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[acid, chemical]</td>\n",
       "      <td>1</td>\n",
       "      <td>13.334236</td>\n",
       "      <td>0.452739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[acoustics, discipline]</td>\n",
       "      <td>1</td>\n",
       "      <td>3.960818</td>\n",
       "      <td>0.168297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[adjective, word]</td>\n",
       "      <td>1</td>\n",
       "      <td>3.691530</td>\n",
       "      <td>0.532800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2069</th>\n",
       "      <td>[writer, dramatist]</td>\n",
       "      <td>0</td>\n",
       "      <td>134.899479</td>\n",
       "      <td>0.576213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070</th>\n",
       "      <td>[writer, poet]</td>\n",
       "      <td>0</td>\n",
       "      <td>186.203409</td>\n",
       "      <td>0.660295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2071</th>\n",
       "      <td>[yellow, protein]</td>\n",
       "      <td>0</td>\n",
       "      <td>17.074218</td>\n",
       "      <td>0.157461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2072</th>\n",
       "      <td>[yesterday, discipline]</td>\n",
       "      <td>0</td>\n",
       "      <td>273.713616</td>\n",
       "      <td>-0.018148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2073</th>\n",
       "      <td>[yesterday, subcommittee]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.764901</td>\n",
       "      <td>0.184361</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2074 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Wordpair  True label    KL score  COS score\n",
       "0        [abstraction, concept]           1    2.201361   0.370621\n",
       "1       [accusation, statement]           1    1.641579   0.477037\n",
       "2              [acid, chemical]           1   13.334236   0.452739\n",
       "3       [acoustics, discipline]           1    3.960818   0.168297\n",
       "4             [adjective, word]           1    3.691530   0.532800\n",
       "...                         ...         ...         ...        ...\n",
       "2069        [writer, dramatist]           0  134.899479   0.576213\n",
       "2070             [writer, poet]           0  186.203409   0.660295\n",
       "2071          [yellow, protein]           0   17.074218   0.157461\n",
       "2072    [yesterday, discipline]           0  273.713616  -0.018148\n",
       "2073  [yesterday, subcommittee]           0    0.764901   0.184361\n",
       "\n",
       "[2074 rows x 4 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COS AP:  0.7378328178113052\n",
      "KL AP:  0.4154657190071638\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "print(\"COS AP: \", average_precision_score(df[\"True label\"], df[\"COS score\"]))\n",
    "print(\"KL AP: \", average_precision_score(df[\"True label\"], df[\"KL score\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "wiki_count = Counter(tqdm(wiki_all_text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle5 as pickle \n",
    "\n",
    "with open('baroniwiki_count.pickle', 'rb') as f:\n",
    "    baroniwiki_count = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, vallue in baroniwiki_count.items():\n",
    "    if vallue == None:\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "629122"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
