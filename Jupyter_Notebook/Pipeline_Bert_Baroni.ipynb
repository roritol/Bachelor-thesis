{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from typing import List\n",
    "from collections import Counter\n",
    "import pickle5 as pickle \n",
    "from tqdm import trange\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "from transformers import (DistilBertTokenizerFast, DistilBertModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Vocab:\n",
    "\n",
    "    def __init__(self):\n",
    "        self._tok_counts = Counter()\n",
    "        self._id_to_tok = {}\n",
    "\n",
    "    def fit(self, data, word_list):\n",
    "        for sequence in data:\n",
    "            self._tok_counts.update([tok for tok in sequence if tok in word_list])\n",
    "\n",
    "        self._toks = ([\"</s>\", \"<unk>\"] +\n",
    "                      [tok for tok, _ in self._tok_counts.most_common()])\n",
    "        self._tok_to_id = {tok: i for i, tok in enumerate(self._toks)}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._toks)\n",
    "    \n",
    "class Tokenizer:\n",
    "\n",
    "    def __init__(self):\n",
    "        self._t = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")\n",
    "    def words(self, sequences: List[str]):\n",
    "        return [s.split() for s in sequences]\n",
    "\n",
    "    def __call__(self, sequences: List[str]):\n",
    "        words = self.words(sequences)\n",
    "        subw = self._t.batch_encode_plus(words,\n",
    "                                         is_split_into_words=True,\n",
    "                                         padding=True)\n",
    "        return words, subw\n",
    "\n",
    "class EmbedAverages(torch.nn.Module):\n",
    "    def __init__(self, n_words, dim):\n",
    "        super().__init__()\n",
    "        # matrix of wordvector sums\n",
    "        self.register_buffer(\"_sum\", torch.zeros(n_words, dim))\n",
    "        self.register_buffer(\"_counts\", torch.zeros(n_words, dtype=torch.long))\n",
    "        self.register_buffer(\"_cov\", torch.zeros(n_words, dim, dim))\n",
    "    \n",
    "    def add(self, ix, vec):\n",
    "        self._counts[ix] += 1\n",
    "        self._sum[ix] += vec\n",
    "        self._cov[ix] += vec.reshape([len(vec), 1]) @ vec.reshape([1, len(vec)])\n",
    "    \n",
    "    def get_mean_covariance(self, ix):\n",
    "#         print(\"self._counts[ix]\", self._counts[ix])\n",
    "#         print(\"self._sum[ix]\", self._sum[ix])\n",
    "        \n",
    "        mean = self._sum[ix] / self._counts[ix]\n",
    "        d = len(mean)\n",
    "        cov = self._cov[ix] / self._counts[ix] - mean.reshape([d, 1])  @ mean.reshape([1, d])\n",
    "        cov = .001 * torch.eye(d) + cov\n",
    "        return mean, cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_kl(wordpair):\n",
    "    # Get the mean vectors and covariance matrices for the two words in the word pair\n",
    "    mean1, covariance_matrix1 = embavg.get_mean_covariance(vocab._tok_to_id.get(wordpair[0])) \n",
    "    mean2, covariance_matrix2 = embavg.get_mean_covariance(vocab._tok_to_id.get(wordpair[1])) \n",
    "    \n",
    "    # Create PyTorch multivariate normal distributions using the mean vectors and covariance matrices\n",
    "    p = torch.distributions.multivariate_normal.MultivariateNormal(mean1, covariance_matrix=covariance_matrix1)\n",
    "    q = torch.distributions.multivariate_normal.MultivariateNormal(mean2, covariance_matrix=covariance_matrix2)\n",
    "\n",
    "    # Calculate the KL divergence between the two distributions\n",
    "    kl = torch.distributions.kl.kl_divergence(p, q)\n",
    "\n",
    "    return kl.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(a, b):\n",
    "    nominator = torch.dot(a, b)\n",
    "    \n",
    "    a_norm = torch.sqrt(torch.sum(a**2))\n",
    "    b_norm = torch.sqrt(torch.sum(b**2))\n",
    "    \n",
    "    denominator = a_norm * b_norm\n",
    "    \n",
    "    cosine_similarity = nominator / denominator\n",
    "    \n",
    "    return cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def import_baroni(neg_file, pos_file):\n",
    "    filenames = [\"neg_file\", \"pos_file\"]\n",
    "\n",
    "    for i, file in enumerate([neg_file, pos_file]):\n",
    "        globals()['results_{}'.format(filenames[i])] = []\n",
    "        \n",
    "        with open(file) as f:\n",
    "            line = f.readline()\n",
    "            while line:\n",
    "                globals()['results_{}'.format(filenames[i])].append(line.replace(\"-n\", \"\").replace(\"\\n\", \"\").strip(\"\").split(\"\\t\"))\n",
    "                line = f.readline()\n",
    "        f.close()\n",
    "\n",
    "    baroni = sum(results_neg_file, []) + sum(results_pos_file, [])\n",
    "    baroni_set = set(baroni)\n",
    "\n",
    "    return results_neg_file, results_pos_file, baroni, baroni_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5163\n"
     ]
    }
   ],
   "source": [
    "# Open the file in read mode\n",
    "with open(\"../data_distrembed/roen.vocab\", \"r\") as f:\n",
    "    # Read the contents of the file\n",
    "    contents = f.read()\n",
    "\n",
    "print(len(contents))  # prints the contents of the file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_file = \"../Data_Shared/eacl2012-data/negative-examples.txtinput\"\n",
    "pos_file = \"../Data_Shared/eacl2012-data/positive-examples.txtinput\"\n",
    "results_neg_file, results_pos_file, baroni, baroni_set = import_baroni(neg_file, pos_file)\n",
    "\n",
    "with open('../Data_Shared/wiki_subtext_preprocess.pickle', 'rb') as handle:\n",
    "        seqs = pickle.load(handle)\n",
    "\n",
    "import ast\n",
    "  \n",
    "# reading the data from the file\n",
    "with open('../Data_shared/wiki_subset.txt') as f:\n",
    "    data = f.read()\n",
    "      \n",
    "# reconstructing the data as a dictionary\n",
    "# wikidata = ast.literal_eval(data)\n",
    "seqs = seqs[:100000]\n",
    "\n",
    "tok = Tokenizer()\n",
    "vocab = Vocab()\n",
    "vocab.fit(tok.words(seqs), baroni)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'</s>': 0,\n",
       " '<unk>': 1,\n",
       " 'people': 2,\n",
       " 'gas': 3,\n",
       " 'song': 4,\n",
       " 'name': 5,\n",
       " 'system': 6,\n",
       " 'funeral': 7,\n",
       " 'music': 8,\n",
       " 'football': 9,\n",
       " 'company': 10,\n",
       " 'player': 11,\n",
       " 'race': 12,\n",
       " 'politician': 13,\n",
       " 'hotel': 14,\n",
       " 'district': 15,\n",
       " 'church': 16,\n",
       " 'member': 17,\n",
       " 'set': 18,\n",
       " 'animal': 19,\n",
       " 'list': 20,\n",
       " 'son': 21,\n",
       " 'area': 22,\n",
       " 'final': 23,\n",
       " 'black': 24,\n",
       " 'energy': 25,\n",
       " 'president': 26,\n",
       " 'day': 27,\n",
       " 'building': 28,\n",
       " 'school': 29,\n",
       " 'ship': 30,\n",
       " 'end': 31,\n",
       " 'army': 32,\n",
       " 'conversion': 33,\n",
       " 'house': 34,\n",
       " 'work': 35,\n",
       " 'official': 36,\n",
       " 'green': 37,\n",
       " 'range': 38,\n",
       " 'organization': 39,\n",
       " 'red': 40,\n",
       " 'premier': 41,\n",
       " 'car': 42,\n",
       " 'father': 43,\n",
       " 'chart': 44,\n",
       " 'information': 45,\n",
       " 'art': 46,\n",
       " 'book': 47,\n",
       " 'community': 48,\n",
       " 'department': 49,\n",
       " 'ten': 50,\n",
       " 'road': 51,\n",
       " 'election': 52,\n",
       " 'governor': 53,\n",
       " 'club': 54,\n",
       " 'joint': 55,\n",
       " 'collection': 56,\n",
       " 'council': 57,\n",
       " 'site': 58,\n",
       " 'hockey': 59,\n",
       " 'record': 60,\n",
       " 'coach': 61,\n",
       " 'poet': 62,\n",
       " 'oil': 63,\n",
       " 'driver': 64,\n",
       " 'man': 65,\n",
       " 'water': 66,\n",
       " 'association': 67,\n",
       " 'term': 68,\n",
       " 'science': 69,\n",
       " 'title': 70,\n",
       " 'point': 71,\n",
       " 'country': 72,\n",
       " 'hall': 73,\n",
       " 'love': 74,\n",
       " 'human': 75,\n",
       " 'singer': 76,\n",
       " 'performance': 77,\n",
       " 'officer': 78,\n",
       " 'right': 79,\n",
       " 'ceremony': 80,\n",
       " 'navy': 81,\n",
       " 'railway': 82,\n",
       " 'business': 83,\n",
       " 'aircraft': 84,\n",
       " 'show': 85,\n",
       " 'wife': 86,\n",
       " 'daughter': 87,\n",
       " 'tour': 88,\n",
       " 'journalist': 89,\n",
       " 'carbon': 90,\n",
       " 'color': 91,\n",
       " 'wood': 92,\n",
       " 'commission': 93,\n",
       " 'studio': 94,\n",
       " 'committee': 95,\n",
       " 'male': 96,\n",
       " 'professional': 97,\n",
       " 'contract': 98,\n",
       " 'change': 99,\n",
       " 'dog': 100,\n",
       " 'light': 101,\n",
       " 'artist': 102,\n",
       " 'crew': 103,\n",
       " 'contest': 104,\n",
       " 'attack': 105,\n",
       " 'comic': 106,\n",
       " 'nickname': 107,\n",
       " 'surface': 108,\n",
       " 'yellow': 109,\n",
       " 'military': 110,\n",
       " 'brigade': 111,\n",
       " 'representative': 112,\n",
       " 'post': 113,\n",
       " 'research': 114,\n",
       " 'engine': 115,\n",
       " 'heat': 116,\n",
       " 'software': 117,\n",
       " 'pope': 118,\n",
       " 'female': 119,\n",
       " 'sir': 120,\n",
       " 'strength': 121,\n",
       " 'polymer': 122,\n",
       " 'hospital': 123,\n",
       " 'basketball': 124,\n",
       " 'quarterback': 125,\n",
       " 'lady': 126,\n",
       " 'metro': 127,\n",
       " 'valley': 128,\n",
       " 'brother': 129,\n",
       " 'woman': 130,\n",
       " 'writer': 131,\n",
       " 'leader': 132,\n",
       " 'concert': 133,\n",
       " 'plant': 134,\n",
       " 'stream': 135,\n",
       " 'courthouse': 136,\n",
       " 'painting': 137,\n",
       " 'size': 138,\n",
       " 'businessman': 139,\n",
       " 'room': 140,\n",
       " 'corporation': 141,\n",
       " 'draft': 142,\n",
       " 'mother': 143,\n",
       " 'review': 144,\n",
       " 'agreement': 145,\n",
       " 'shrine': 146,\n",
       " 'text': 147,\n",
       " 'pearl': 148,\n",
       " 'opening': 149,\n",
       " 'ice': 150,\n",
       " 'locomotive': 151,\n",
       " 'machine': 152,\n",
       " 'concept': 153,\n",
       " 'monastery': 154,\n",
       " 'husband': 155,\n",
       " 'note': 156,\n",
       " 'fish': 157,\n",
       " 'fiber': 158,\n",
       " 'playing': 159,\n",
       " 'bronze': 160,\n",
       " 'screenwriter': 161,\n",
       " 'word': 162,\n",
       " 'bishop': 163,\n",
       " 'cafe': 164,\n",
       " 'magazine': 165,\n",
       " 'game': 166,\n",
       " 'edge': 167,\n",
       " 'meat': 168,\n",
       " 'investment': 169,\n",
       " 'snake': 170,\n",
       " 'practice': 171,\n",
       " 'pilot': 172,\n",
       " 'piece': 173,\n",
       " 'turkey': 174,\n",
       " 'slalom': 175,\n",
       " 'gate': 176,\n",
       " 'box': 177,\n",
       " 'cat': 178,\n",
       " 'wall': 179,\n",
       " 'entrance': 180,\n",
       " 'encyclopedia': 181,\n",
       " 'treatment': 182,\n",
       " 'child': 183,\n",
       " 'prose': 184,\n",
       " 'cost': 185,\n",
       " 'produce': 186,\n",
       " 'wind': 187,\n",
       " 'horse': 188,\n",
       " 'bridge': 189,\n",
       " 'solid': 190,\n",
       " 'highway': 191,\n",
       " 'orange': 192,\n",
       " 'value': 193,\n",
       " 'engineering': 194,\n",
       " 'receiver': 195,\n",
       " 'vi': 196,\n",
       " 'vehicle': 197,\n",
       " 'anniversary': 198,\n",
       " 'theology': 199,\n",
       " 'dinner': 200,\n",
       " 'section': 201,\n",
       " 'musician': 202,\n",
       " 'ability': 203,\n",
       " 'solution': 204,\n",
       " 'soldier': 205,\n",
       " 'eating': 206,\n",
       " 'letter': 207,\n",
       " 'floor': 208,\n",
       " 'educator': 209,\n",
       " 'artillery': 210,\n",
       " 'racing': 211,\n",
       " 'screen': 212,\n",
       " 'rain': 213,\n",
       " 'cancer': 214,\n",
       " 'fuel': 215,\n",
       " 'twenty': 216,\n",
       " 'liquid': 217,\n",
       " 'chair': 218,\n",
       " 'era': 219,\n",
       " 'castle': 220,\n",
       " 'travel': 221,\n",
       " 'entertainment': 222,\n",
       " 'dancing': 223,\n",
       " 'height': 224,\n",
       " 'thirty': 225,\n",
       " 'statement': 226,\n",
       " 'temperature': 227,\n",
       " 'radius': 228,\n",
       " 'ban': 229,\n",
       " 'milk': 230,\n",
       " 'firm': 231,\n",
       " 'gun': 232,\n",
       " 'voice': 233,\n",
       " 'criminal': 234,\n",
       " 'iv': 235,\n",
       " 'suburb': 236,\n",
       " 'eagle': 237,\n",
       " 'golf': 238,\n",
       " 'care': 239,\n",
       " 'priest': 240,\n",
       " 'food': 241,\n",
       " 'flower': 242,\n",
       " 'superior': 243,\n",
       " 'movie': 244,\n",
       " 'leg': 245,\n",
       " 'representation': 246,\n",
       " 'diplomat': 247,\n",
       " 'teacher': 248,\n",
       " 'housing': 249,\n",
       " 'radiation': 250,\n",
       " 'chemical': 251,\n",
       " 'drummer': 252,\n",
       " 'winner': 253,\n",
       " 'occupation': 254,\n",
       " 'platform': 255,\n",
       " 'medium': 256,\n",
       " 'journey': 257,\n",
       " 'cold': 258,\n",
       " 'cannon': 259,\n",
       " 'scientist': 260,\n",
       " 'manual': 261,\n",
       " 'turnpike': 262,\n",
       " 'curve': 263,\n",
       " 'skier': 264,\n",
       " 'consumption': 265,\n",
       " 'border': 266,\n",
       " 'economics': 267,\n",
       " 'jean': 268,\n",
       " 'host': 269,\n",
       " 'reliability': 270,\n",
       " 'buffalo': 271,\n",
       " 'theater': 272,\n",
       " 'chapel': 273,\n",
       " 'saying': 274,\n",
       " 'lecturer': 275,\n",
       " 'cemetery': 276,\n",
       " 'mail': 277,\n",
       " 'manor': 278,\n",
       " 'disease': 279,\n",
       " 'conflict': 280,\n",
       " 'speaker': 281,\n",
       " 'discussion': 282,\n",
       " 'wine': 283,\n",
       " 'dramatist': 284,\n",
       " 'dancer': 285,\n",
       " 'bread': 286,\n",
       " 'athlete': 287,\n",
       " 'boat': 288,\n",
       " 'pine': 289,\n",
       " 'servant': 290,\n",
       " 'pair': 291,\n",
       " 'kick': 292,\n",
       " 'computer': 293,\n",
       " 'tip': 294,\n",
       " 'cool': 295,\n",
       " 'dean': 296,\n",
       " 'submarine': 297,\n",
       " 'meeting': 298,\n",
       " 'mule': 299,\n",
       " 'wave': 300,\n",
       " 'payment': 301,\n",
       " 'twelve': 302,\n",
       " 'cricketer': 303,\n",
       " 'facility': 304,\n",
       " 'cricket': 305,\n",
       " 'organist': 306,\n",
       " 'physician': 307,\n",
       " 'motorcycle': 308,\n",
       " 'tool': 309,\n",
       " 'winger': 310,\n",
       " 'baby': 311,\n",
       " 'prefecture': 312,\n",
       " 'merchant': 313,\n",
       " 'ancestor': 314,\n",
       " 'furniture': 315,\n",
       " 'antiquity': 316,\n",
       " 'decree': 317,\n",
       " 'document': 318,\n",
       " 'monarch': 319,\n",
       " 'reelection': 320,\n",
       " 'status': 321,\n",
       " 'recovery': 322,\n",
       " 'apple': 323,\n",
       " 'adult': 324,\n",
       " 'passion': 325,\n",
       " 'scholar': 326,\n",
       " 'spiral': 327,\n",
       " 'eleven': 328,\n",
       " 'cheese': 329,\n",
       " 'standing': 330,\n",
       " 'compensation': 331,\n",
       " 'orator': 332,\n",
       " 'doctor': 333,\n",
       " 'equipment': 334,\n",
       " 'geometry': 335,\n",
       " 'depth': 336,\n",
       " 'crystal': 337,\n",
       " 'consumer': 338,\n",
       " 'resident': 339,\n",
       " 'mathematics': 340,\n",
       " 'vocalist': 341,\n",
       " 'publisher': 342,\n",
       " 'attorney': 343,\n",
       " 'deer': 344,\n",
       " 'communication': 345,\n",
       " 'storm': 346,\n",
       " 'campsite': 347,\n",
       " 'walk': 348,\n",
       " 'vessel': 349,\n",
       " 'tower': 350,\n",
       " 'covering': 351,\n",
       " 'symbol': 352,\n",
       " 'crusade': 353,\n",
       " 'champagne': 354,\n",
       " 'theatre': 355,\n",
       " 'olive': 356,\n",
       " 'fly': 357,\n",
       " 'missile': 358,\n",
       " 'motto': 359,\n",
       " 'rate': 360,\n",
       " 'chancellor': 361,\n",
       " 'sunlight': 362,\n",
       " 'taste': 363,\n",
       " 'artwork': 364,\n",
       " 'murder': 365,\n",
       " 'therapy': 366,\n",
       " 'sunshine': 367,\n",
       " 'soccer': 368,\n",
       " 'principle': 369,\n",
       " 'publication': 370,\n",
       " 'postgraduate': 371,\n",
       " 'signal': 372,\n",
       " 'petroleum': 373,\n",
       " 'rector': 374,\n",
       " 'pianist': 375,\n",
       " 'knife': 376,\n",
       " 'restaurant': 377,\n",
       " 'sociologist': 378,\n",
       " 'declaration': 379,\n",
       " 'security': 380,\n",
       " 'caucus': 381,\n",
       " 'motorway': 382,\n",
       " 'epic': 383,\n",
       " 'biology': 384,\n",
       " 'cottage': 385,\n",
       " 'dish': 386,\n",
       " 'priory': 387,\n",
       " 'worm': 388,\n",
       " 'difference': 389,\n",
       " 'bull': 390,\n",
       " 'seminary': 391,\n",
       " 'ruler': 392,\n",
       " 'advocate': 393,\n",
       " 'cowboy': 394,\n",
       " 'humanist': 395,\n",
       " 'pain': 396,\n",
       " 'courtroom': 397,\n",
       " 'student': 398,\n",
       " 'aristocrat': 399,\n",
       " 'victim': 400,\n",
       " 'illness': 401,\n",
       " 'velocity': 402,\n",
       " 'surprise': 403,\n",
       " 'editor': 404,\n",
       " 'convention': 405,\n",
       " 'performer': 406,\n",
       " 'lamb': 407,\n",
       " 'dealer': 408,\n",
       " 'moratorium': 409,\n",
       " 'ticket': 410,\n",
       " 'gauge': 411,\n",
       " 'pipe': 412,\n",
       " 'cradle': 413,\n",
       " 'institution': 414,\n",
       " 'odyssey': 415,\n",
       " 'documentary': 416,\n",
       " 'clerk': 417,\n",
       " 'gunner': 418,\n",
       " 'pocket': 419,\n",
       " 'math': 420,\n",
       " 'fruit': 421,\n",
       " 'radar': 422,\n",
       " 'surgeon': 423,\n",
       " 'grove': 424,\n",
       " 'teaching': 425,\n",
       " 'whisky': 426,\n",
       " 'spacecraft': 427,\n",
       " 'sport': 428,\n",
       " 'shareholder': 429,\n",
       " 'memorandum': 430,\n",
       " 'fork': 431,\n",
       " 'procedure': 432,\n",
       " 'aide': 433,\n",
       " 'piracy': 434,\n",
       " 'royalty': 435,\n",
       " 'nut': 436,\n",
       " 'acid': 437,\n",
       " 'crime': 438,\n",
       " 'dictionary': 439,\n",
       " 'inn': 440,\n",
       " 'vicinity': 441,\n",
       " 'decoration': 442,\n",
       " 'chamber': 443,\n",
       " 'belief': 444,\n",
       " 'bear': 445,\n",
       " 'battleship': 446,\n",
       " 'commerce': 447,\n",
       " 'biologist': 448,\n",
       " 'sailor': 449,\n",
       " 'automobile': 450,\n",
       " 'violinist': 451,\n",
       " 'rugby': 452,\n",
       " 'archbishop': 453,\n",
       " 'linguist': 454,\n",
       " 'convent': 455,\n",
       " 'affection': 456,\n",
       " 'sixty': 457,\n",
       " 'dance': 458,\n",
       " 'initiation': 459,\n",
       " 'mixture': 460,\n",
       " 'stereo': 461,\n",
       " 'pathology': 462,\n",
       " 'fox': 463,\n",
       " 'slogan': 464,\n",
       " 'corridor': 465,\n",
       " 'barrier': 466,\n",
       " 'medicine': 467,\n",
       " 'environmentalist': 468,\n",
       " 'experiment': 469,\n",
       " 'snail': 470,\n",
       " 'cow': 471,\n",
       " 'deity': 472,\n",
       " 'lion': 473,\n",
       " 'logo': 474,\n",
       " 'passageway': 475,\n",
       " 'disability': 476,\n",
       " 'pet': 477,\n",
       " 'epistle': 478,\n",
       " 'spokesman': 479,\n",
       " 'message': 480,\n",
       " 'turbine': 481,\n",
       " 'registry': 482,\n",
       " 'baroness': 483,\n",
       " 'tutor': 484,\n",
       " 'palace': 485,\n",
       " 'garment': 486,\n",
       " 'kidnapping': 487,\n",
       " 'hair': 488,\n",
       " 'stepfather': 489,\n",
       " 'serpent': 490,\n",
       " 'prosecutor': 491,\n",
       " 'waiter': 492,\n",
       " 'joker': 493,\n",
       " 'gown': 494,\n",
       " 'sandwich': 495,\n",
       " 'decrease': 496,\n",
       " 'pontoon': 497,\n",
       " 'telegraph': 498,\n",
       " 'dove': 499,\n",
       " 'fencing': 500,\n",
       " 'swimming': 501,\n",
       " 'taxonomy': 502,\n",
       " 'lemon': 503,\n",
       " 'mistress': 504,\n",
       " 'condominium': 505,\n",
       " 'penthouse': 506,\n",
       " 'beverage': 507,\n",
       " 'virus': 508,\n",
       " 'pig': 509,\n",
       " 'pear': 510,\n",
       " 'alcohol': 511,\n",
       " 'flour': 512,\n",
       " 'paddle': 513,\n",
       " 'pirate': 514,\n",
       " 'feeling': 515,\n",
       " 'musket': 516,\n",
       " 'hawk': 517,\n",
       " 'shovel': 518,\n",
       " 'arthritis': 519,\n",
       " 'polyethylene': 520,\n",
       " 'explosive': 521,\n",
       " 'bend': 522,\n",
       " 'bird': 523,\n",
       " 'carbonate': 524,\n",
       " 'cassette': 525,\n",
       " 'melon': 526,\n",
       " 'relief': 527,\n",
       " 'transformation': 528,\n",
       " 'doctrine': 529,\n",
       " 'cosmology': 530,\n",
       " 'dwelling': 531,\n",
       " 'suit': 532,\n",
       " 'herb': 533,\n",
       " 'seed': 534,\n",
       " 'jet': 535,\n",
       " 'secretariat': 536,\n",
       " 'counterattack': 537,\n",
       " 'rifle': 538,\n",
       " 'ferry': 539,\n",
       " 'hamlet': 540,\n",
       " 'tavern': 541,\n",
       " 'militia': 542,\n",
       " 'sociology': 543,\n",
       " 'vicar': 544,\n",
       " 'typography': 545,\n",
       " 'believer': 546,\n",
       " 'panic': 547,\n",
       " 'bassist': 548,\n",
       " 'raven': 549,\n",
       " 'skating': 550,\n",
       " 'observatory': 551,\n",
       " 'ink': 552,\n",
       " 'alpha': 553,\n",
       " 'ox': 554,\n",
       " 'parent': 555,\n",
       " 'captivity': 556,\n",
       " 'secret': 557,\n",
       " 'volleyball': 558,\n",
       " 'cycling': 559,\n",
       " 'rig': 560,\n",
       " 'helicopter': 561,\n",
       " 'pizza': 562,\n",
       " 'quartz': 563,\n",
       " 'resin': 564,\n",
       " 'optimism': 565,\n",
       " 'competitiveness': 566,\n",
       " 'comment': 567,\n",
       " 'tree': 568,\n",
       " 'pollen': 569,\n",
       " 'migration': 570,\n",
       " 'vandalism': 571,\n",
       " 'undertaking': 572,\n",
       " 'gymnasium': 573,\n",
       " 'invitation': 574,\n",
       " 'carpenter': 575,\n",
       " 'elite': 576,\n",
       " 'mosque': 577,\n",
       " 'attitude': 578,\n",
       " 'compassion': 579,\n",
       " 'stipend': 580,\n",
       " 'seaplane': 581,\n",
       " 'seaman': 582,\n",
       " 'cook': 583,\n",
       " 'maple': 584,\n",
       " 'regent': 585,\n",
       " 'empress': 586,\n",
       " 'crab': 587,\n",
       " 'infant': 588,\n",
       " 'throne': 589,\n",
       " 'crowd': 590,\n",
       " 'tank': 591,\n",
       " 'bomber': 592,\n",
       " 'butcher': 593,\n",
       " 'balloon': 594,\n",
       " 'swan': 595,\n",
       " 'economist': 596,\n",
       " 'soprano': 597,\n",
       " 'swimmer': 598,\n",
       " 'percussionist': 599,\n",
       " 'saxophonist': 600,\n",
       " 'sprinter': 601,\n",
       " 'birthday': 602,\n",
       " 'boundary': 603,\n",
       " 'documentation': 604,\n",
       " 'license': 605,\n",
       " 'staple': 606,\n",
       " 'transaction': 607,\n",
       " 'trainer': 608,\n",
       " 'tie': 609,\n",
       " 'disco': 610,\n",
       " 'bottle': 611,\n",
       " 'rider': 612,\n",
       " 'hypnotherapy': 613,\n",
       " 'apparatus': 614,\n",
       " 'goalkeeper': 615,\n",
       " 'sedan': 616,\n",
       " 'pathologist': 617,\n",
       " 'physiology': 618,\n",
       " 'orchid': 619,\n",
       " 'sound': 620,\n",
       " 'shirt': 621,\n",
       " 'chemistry': 622,\n",
       " 'shop': 623,\n",
       " 'tea': 624,\n",
       " 'craftsman': 625,\n",
       " 'grandmother': 626,\n",
       " 'spoon': 627,\n",
       " 'spaceship': 628,\n",
       " 'organ': 629,\n",
       " 'rue': 630,\n",
       " 'obstruction': 631,\n",
       " 'cardinal': 632,\n",
       " 'hierarchy': 633,\n",
       " 'salesman': 634,\n",
       " 'detective': 635,\n",
       " 'storyteller': 636,\n",
       " 'reptile': 637,\n",
       " 'robin': 638,\n",
       " 'dad': 639,\n",
       " 'bacterium': 640,\n",
       " 'weapon': 641,\n",
       " 'pistol': 642,\n",
       " 'psychology': 643,\n",
       " 'coupe': 644,\n",
       " 'berry': 645,\n",
       " 'mom': 646,\n",
       " 'physiotherapy': 647,\n",
       " 'narrative': 648,\n",
       " 'electronics': 649,\n",
       " 'logic': 650,\n",
       " 'combustion': 651,\n",
       " 'relative': 652,\n",
       " 'goat': 653,\n",
       " 'cotton': 654,\n",
       " 'baronetcy': 655,\n",
       " 'pony': 656,\n",
       " 'beard': 657,\n",
       " 'bat': 658,\n",
       " 'hamster': 659,\n",
       " 'sack': 660,\n",
       " 'fear': 661,\n",
       " 'roast': 662,\n",
       " 'sweetness': 663,\n",
       " 'candy': 664,\n",
       " 'chef': 665,\n",
       " 'cookie': 666,\n",
       " 'dolphin': 667,\n",
       " 'boulevard': 668,\n",
       " 'columnist': 669,\n",
       " 'bounty': 670,\n",
       " 'resignation': 671}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab._tok_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "embavg = torch.load('../data_distrembed/first100000.avgs.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "670\n"
     ]
    }
   ],
   "source": [
    "print(len(vocab._tok_counts))\n",
    "# print(vocab._tok_counts)\n",
    "for key, item in vocab._tok_counts.items():\n",
    "    if key not in baroni:\n",
    "        print(key, item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "baroni_pos_subset = [x for x in results_pos_file if x[0] in vocab._tok_counts and x[1] in vocab._tok_counts]\n",
    "baroni_neg_subset = [x for x in results_neg_file if x[0] in vocab._tok_counts and x[1] in vocab._tok_counts]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Wordpair  True label\n",
      "0        [acid, chemical]           1\n",
      "1    [affection, feeling]           1\n",
      "2     [aircraft, vehicle]           1\n",
      "3         [alpha, symbol]           1\n",
      "4        [antiquity, era]           1\n",
      "..                    ...         ...\n",
      "732     [woman, mistress]           0\n",
      "733         [wood, maple]           0\n",
      "734          [work, bird]           0\n",
      "735   [writer, dramatist]           0\n",
      "736        [writer, poet]           0\n",
      "\n",
      "[737 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# baroni_pos_subset, baroni_neg_subset = create_combined_subset(word_cov_matrices, results_neg_file, results_pos_file, combined_set)\n",
    "\n",
    "baroni_subset_label = []\n",
    "\n",
    "for i in baroni_pos_subset:\n",
    "    baroni_subset_label.append([i, 1])\n",
    "\n",
    "for i in baroni_neg_subset:\n",
    "    baroni_subset_label.append([i, 0])\n",
    "\n",
    "# MAKE DATAFRAME\n",
    "df1 = pd.DataFrame(baroni_subset_label, columns =['Wordpair', 'True label'])\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "baroni_subset_cos = []\n",
    "\n",
    "for wordpair in (baroni_pos_subset + baroni_neg_subset):\n",
    "    A = embavg._sum[vocab._tok_to_id.get(wordpair[0])]\n",
    "    B = embavg._sum[vocab._tok_to_id.get(wordpair[1])]\n",
    "    baroni_subset_cos.append(torch.cosine_similarity(A, B))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate KL and COS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 737/737 [01:02<00:00, 11.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Wordpair  True label      KL score       COS score\n",
      "0        [acid, chemical]           1  22588.404297  tensor(0.7882)\n",
      "1    [affection, feeling]           1  24089.642578  tensor(0.7085)\n",
      "2     [aircraft, vehicle]           1  22337.914062  tensor(0.7861)\n",
      "3         [alpha, symbol]           1  47081.132812  tensor(0.6093)\n",
      "4        [antiquity, era]           1  34338.492188  tensor(0.6267)\n",
      "..                    ...         ...           ...             ...\n",
      "732     [woman, mistress]           0  33531.156250  tensor(0.6877)\n",
      "733         [wood, maple]           0  25387.968750  tensor(0.7393)\n",
      "734          [work, bird]           0  37608.054688  tensor(0.6506)\n",
      "735   [writer, dramatist]           0  50024.500000  tensor(0.6341)\n",
      "736        [writer, poet]           0  19814.851562  tensor(0.8291)\n",
      "\n",
      "[737 rows x 4 columns]\n",
      "COS AP:  0.6932439050975777\n",
      "KL AP:  0.6869634675826695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# CALCULATE KL and COS\n",
    "baroni_subset_kl = []\n",
    "baroni_subset_cos = []\n",
    "\n",
    "for wordpair in tqdm((baroni_pos_subset + baroni_neg_subset)):\n",
    "    baroni_subset_kl.append(calculate_kl(wordpair))\n",
    "    baroni_subset_cos.append(cosine_similarity(embavg._sum[vocab._tok_to_id.get(wordpair[0])], \n",
    "                                               embavg._sum[vocab._tok_to_id.get(wordpair[1])]))\n",
    "\n",
    "df1['KL score'] = baroni_subset_kl\n",
    "df1['COS score'] = baroni_subset_cos\n",
    "\n",
    "# with open('df1.pickle', 'wb') as handle:\n",
    "#     pickle.dump(df1, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "print(df1)\n",
    "print(\"COS AP: \", average_precision_score(df1[\"True label\"], df1[\"COS score\"]))\n",
    "print(\"KL AP: \", average_precision_score(df1[\"True label\"], -df1[\"KL score\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
